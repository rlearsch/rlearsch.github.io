{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18466480-482f-4086-98f5-c7ead0a545ed",
   "metadata": {},
   "source": [
    "# TDC ADMET, Caco-2_Wang Submission\n",
    "The structure for this model was originally written by Lealia Xiong, and it is used with permission and attribution. Modifications including scaling the y values and tuning the hyperparameters were done by Rob Learsch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c86952a-47f8-4e3d-a22e-36ecfe207217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# cheminformatics\n",
    "import rdkit.Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "# logging\n",
    "import tqdm\n",
    "\n",
    "# data preprocessing\n",
    "import sklearn.impute\n",
    "import sklearn.preprocessing\n",
    "\n",
    "# modeling\n",
    "import sklearn.ensemble\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# metrics\n",
    "import sklearn.metrics\n",
    "\n",
    "from tdc.single_pred import ADME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee27599-741d-4e64-a737-e71ec9094266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data = ADME(name = 'Caco2_Wang')\n",
    "split = data.get_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ea5838-436a-44e0-add0-549ff410ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_descriptor_columns(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Use rdkit to get descriptors of each drug in the `data` df.\n",
    "    Return a Pandas DataFrame with the descriptors as columns in the df and .\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the Drug column\n",
    "    assert 'Drug' in data.columns, \"'Drug' must be a column in the input DataFrame.\"\n",
    "    drugs = data['Drug']\n",
    "    y = data['Y']\n",
    "    \n",
    "    # Get the descriptors for each drug\n",
    "    print(\"Calculating descriptors...\")\n",
    "    descriptors = []\n",
    "    for drug, target in tqdm.tqdm(zip(drugs, y)):\n",
    "        descriptor = Descriptors.CalcMolDescriptors(\n",
    "            rdkit.Chem.MolFromSmiles(drug)\n",
    "        )\n",
    "        descriptor['Drug'] = drug\n",
    "        descriptor['Y'] = target\n",
    "        descriptors.append(descriptor)\n",
    "\n",
    "    # Make a dataframe for the descriptors\n",
    "    df = pd.DataFrame(descriptors)\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocess_data(\n",
    "    data: pd.DataFrame, \n",
    "    imputer=sklearn.impute.SimpleImputer(missing_values=np.nan, strategy='mean'),\n",
    "    fit_imputer=True,\n",
    "    scaler_X=sklearn.preprocessing.RobustScaler(),\n",
    "    scaler_y=sklearn.preprocessing.RobustScaler(),\n",
    "    fit_scaler=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Imputes missing values.\n",
    "    Scales feature data.\n",
    "\n",
    "    Returns a tuple X, y of scaled feature data and target data.\n",
    "    \"\"\"\n",
    "\n",
    "    col_array = np.array(data.columns)\n",
    "\n",
    "    # extract just the feature data\n",
    "    X = data[col_array[~np.isin(col_array, ['Drug_ID', 'Drug', 'Y'])]].to_numpy()\n",
    "    \n",
    "    # extract the target data\n",
    "    y = np.array(data['Y']).reshape(-1,1)\n",
    "    \n",
    "    # impute missing data\n",
    "    if imputer is not None:\n",
    "        if fit_imputer:\n",
    "            X = imputer.fit_transform(X)\n",
    "        else:\n",
    "            X = imputer.transform(X)\n",
    "\n",
    "    # scale the feature data\n",
    "    if scaler_X is not None:\n",
    "        if fit_scaler:\n",
    "            X = scaler_X.fit_transform(X)\n",
    "            y = scaler_y.fit_transform(y)\n",
    "        else:\n",
    "            X = scaler_X.transform(X)\n",
    "            y = scaler_y.transform(y)\n",
    "\n",
    "\n",
    "\n",
    "    return X, y, imputer, scaler_X, scaler_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e6010f6-e6e6-4c7d-ae76-f608faef7d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "637it [00:05, 106.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91it [00:00, 116.30it/s]\n"
     ]
    }
   ],
   "source": [
    "regr = sklearn.ensemble.GradientBoostingRegressor()\n",
    "X_train, y_train, imputer, scaler_X, scaler_y = preprocess_data(add_descriptor_columns(split['train']))\n",
    "X_val, y_val, _, _,_ = preprocess_data(\n",
    "    add_descriptor_columns(split['valid']),\n",
    "    imputer=imputer, fit_imputer=False,\n",
    "    scaler_X=scaler_X, scaler_y=scaler_y,\n",
    "    fit_scaler=False\n",
    ")\n",
    "regr.fit(X_train, y_train)\n",
    "y_val_pred = regr.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0507e02d-d16e-47d4-a334-08d4633ca7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [    \n",
    "    {'subsample' : np.linspace(0.5,0.9,5),   # Used to specify the norm used in the penalization.\n",
    "    'learning_rate': [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07], \n",
    "    'n_estimators': [100, 125, 150, 175, 200, 225, 250,],\n",
    "    }\n",
    "]\n",
    "best_score = sklearn.metrics.mean_absolute_error(y_val, y_val_pred)\n",
    "best_set = {}\n",
    "for param_set in ParameterGrid(params):\n",
    "    regr = sklearn.ensemble.GradientBoostingRegressor(\n",
    "    random_state=1,\n",
    "    )\n",
    "    regr.set_params(**param_set)\n",
    "    regr.fit(X_train,y_train)\n",
    "    score_MAE = sklearn.metrics.mean_absolute_error(y_val, regr.predict(X_val))\n",
    "    #lower is better\n",
    "    # save if best\n",
    "    if score_MAE < best_score:\n",
    "        best_score = score_MAE\n",
    "        best_set = param_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d9d73bc-92b0-4527-be3e-04bdff7a1f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 1:\n",
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "728it [00:06, 112.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [00:01, 108.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 2:\n",
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "728it [00:06, 115.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [00:01, 112.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 3:\n",
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "728it [00:06, 115.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [00:01, 112.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 4:\n",
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "728it [00:06, 110.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [00:01, 104.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 5:\n",
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "728it [00:06, 111.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [00:01, 110.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'caco2_wang': [0.274, 0.004]}\n"
     ]
    }
   ],
   "source": [
    "from tdc.benchmark_group import admet_group\n",
    "group = admet_group(path = 'data/')\n",
    "predictions_list = []\n",
    "for seed in [1, 2, 3, 4, 5]:\n",
    "    benchmark = group.get('Caco2_Wang') \n",
    "    predictions = {}\n",
    "    name = benchmark['name']\n",
    "    train, test = benchmark['train_val'], benchmark['test']\n",
    "    print(f\"Seed {seed}:\")\n",
    "    X_train, y_train, imputer, scaler_X, scaler_y = preprocess_data(add_descriptor_columns(train))\n",
    "    X_test, y_test, _, _, _ = preprocess_data(\n",
    "        add_descriptor_columns(test), \n",
    "        imputer=imputer, fit_imputer=False, \n",
    "        scaler_X=scaler_X, fit_scaler=False, \n",
    "        scaler_y=scaler_y\n",
    "    )\n",
    "    \n",
    "    regr = sklearn.ensemble.GradientBoostingRegressor(\n",
    "        random_state=seed,\n",
    "    )\n",
    "    regr.set_params(**best_set)\n",
    "    regr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_test_scaled = regr.predict(X_test)\n",
    "    y_pred_test = scaler_y.inverse_transform(y_pred_test_scaled.reshape(-1,1))\n",
    "    y_pred_test = y_pred_test.reshape(-1)\n",
    "    \n",
    "    predictions = {}\n",
    "    prediction_dict = {name: y_pred_test}\n",
    "    predictions_list.append(prediction_dict)\n",
    "    \n",
    "results = group.evaluate_many(predictions_list)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afc9e69b-0193-4889-a480-c85bace1000f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 21\n"
     ]
    }
   ],
   "source": [
    "print('Number of parameters: '+str(len(regr.get_params())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de2ea8c5-4cca-451d-8e63-42efc5f099e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.9,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.06,\n",
       " 'loss': 'squared_error',\n",
       " 'max_depth': 3,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 250,\n",
       " 'n_iter_no_change': None,\n",
       " 'random_state': 5,\n",
       " 'subsample': 0.5,\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.get_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
